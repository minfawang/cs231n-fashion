{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables.\n",
    "hidden_size = 100\n",
    "num_classes = 228\n",
    "learning_rate = 3e-4\n",
    "num_train_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for fashion classes predictions.\n",
    "    \n",
    "    Inputs:\n",
    "        features: dict.\n",
    "            Required key: \"image\". The value needs to have shape (batch_size, 299, 299, 3),\n",
    "                and each value needs to be in range [0, 1].\n",
    "        labels: shape (batch_size, num_classes)\n",
    "        mode: tf.estimator.ModeKeys.(PREDICT|TRAIN|EVAL)\n",
    "    \n",
    "    Returns:\n",
    "        estimator_spec.\n",
    "    \"\"\"\n",
    "    # class_prob > threshold will be outputted.\n",
    "    thresholds =[0.3, 0.5, 0.7]\n",
    "    threshold = 0.5\n",
    "#     threshold = tf.get_variable('threshold_unbound', initializer=0.5)\n",
    "#     threshold = tf.clip_by_value(threshold, 0.1, 0.9, name='threshold')\n",
    "    \n",
    "    # Input layer.\n",
    "    images = features['image']\n",
    "    module = hub.Module(\"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/1\")\n",
    "    features = module(images)  # (batch_size, D)\n",
    "    \n",
    "    # Create multi-head sigmoid outputs.\n",
    "    # It measures the independent probability of a class showing in the image.\n",
    "    raw_logits = tf.contrib.layers.fully_connected(\n",
    "        inputs=features,\n",
    "        num_outputs=num_classes,\n",
    "        activation_fn=None)  # (batch_size, num_classes)\n",
    "    \n",
    "    raw_probs = tf.sigmoid(raw_logits)  # (batch_size, num_classes)\n",
    "    \n",
    "#     # RNN layer.\n",
    "#     gru_cell = tf.nn.rnn_cell.GRUCell(hidden_size)\n",
    "#     outputs, _ = tf.nn.dynamic_rnn(cell=gru_cell, inputs=)\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': raw_probs > threshold,\n",
    "        'probs': raw_probs,\n",
    "    }\n",
    "    \n",
    "    # PREDICT mode.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # Calculate loss (for both TRAIN and EVAL mode).\n",
    "    loss = tf.losses.sigmoid_cross_entropy(\n",
    "        multi_class_labels=labels,\n",
    "        logits=raw_logits)\n",
    "    \n",
    "    # TRAIN mode.\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)    \n",
    "    \n",
    "    # Add evalutaion metrics (for EVAL mode).\n",
    "    precisions = tf.metrics.precision_at_thresholds(\n",
    "        labels=labels,\n",
    "        predictions=predictions['probs'],\n",
    "        thresholds=thresholds)\n",
    "    recalls = tf.metrics.recall_at_thresholds(\n",
    "        labels=labels,\n",
    "        predictions=predictions['probs'],\n",
    "        thresholds=thresholds)\n",
    "    auc = tf.metrics.auc(\n",
    "        labels=labels,\n",
    "        predictions=predictions['probs'],\n",
    "        thresholds=thresholds)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'auc': auc,\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_dir/baseline', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94183ebe80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the estimator.\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir='model_dir/baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define input_fn.\n",
    "classifier.train(input_fn, steps=num_train_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n-fashion",
   "language": "python",
   "name": "cs231n-fashion"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
